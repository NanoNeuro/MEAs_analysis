{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from probeinterface.plotting import plot_probe\n",
    "\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import spikeinterface.full as si  # import core only\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.curation as scur\n",
    "import spikeinterface.widgets as sw\n",
    "from spikeinterface.sortingcomponents.peak_detection import detect_peaks\n",
    "from spikeinterface.sortingcomponents.peak_localization import localize_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from py_functions.spikeinterface_processing import load_recording_from_raw, load_probe_recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_job_kwargs = dict(n_jobs=10, chunk_duration=\"1s\")\n",
    "si.set_global_job_kwargs(**global_job_kwargs)\n",
    "plt.rcParams['figure.dpi'] = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN PARAMS\n",
    "ROOT = '/mnt/c/Users/alexm/OneDrive/EBRAINS/MEAs_analysis/data/'\n",
    "SAMPLE_BASE = 'D109'\n",
    "well = (1, 1)\n",
    "time_samplings_to_mask = []\n",
    "type_MEAS = 16  # 16 or 64\n",
    "\n",
    "session_token = datetime.now().strftime(\"%y-%m-%d\") + '_' + \\\n",
    "                ''.join(random.choice(string.ascii_letters) for i in range(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading & preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = load_recording_from_raw(root=ROOT, sample_base=SAMPLE_BASE, well=well, time_samplings_to_mask=time_samplings_to_mask)\n",
    "load_probe_recording(recording=recording, type_MEAS=type_MEAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_bin = recording.save(n_jobs=8, chunk_duration=\"1s\", folder=f'{ROOT}/tmp/bin_{session_token}')\n",
    "\n",
    "recording_f = spre.bandpass_filter(recording_bin, freq_min=300, freq_max=5000)\n",
    "\n",
    "recording_cmr = spre.common_reference(recording_f, reference='global', operator='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_timeseries(recording_cmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise detection - we use this beforehand to later use in peak detection\n",
    "\n",
    "noise_levels = si.get_noise_levels(recording_cmr, return_scaled=False)\n",
    "\n",
    "plt.hist(noise_levels)\n",
    "plt.xlabel('noise  [uV]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_radius = 150   # circle radius x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = detect_peaks(recording_cmr,\n",
    "                     method='locally_exclusive',\n",
    "                     radius_um=local_radius, \n",
    "                     detect_threshold=5,\n",
    "                     noise_levels=noise_levels,\n",
    "                    **global_job_kwargs)\n",
    "\n",
    "peaks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs_path = '/home/alex/Programs'\n",
    "!cd {programs_path} &&  git clone https://github.com/csn-le/wave_clus\n",
    "\n",
    "!ls {programs_path}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {programs_path}/pykilosort && python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.WaveClusSorter.set_waveclus_path(f'{programs_path}/wave_clus')\n",
    "\n",
    "sorting_xoxo = ss.run_sorter(sorter_name=\"waveclus\", recording=recording_cmr,output_folder=f'{ROOT}/tmp/XOXO6_{session_token}', \n",
    "                              docker_image=False)\n",
    "print('Units found by xoxo:', sorting_xoxo.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think it works but it's taking too long in the laptop\n",
    "sorting_TRDC = ss.run_sorter('tridesclous', recording=recording_cmr, \n",
    "                              output_folder=f'{ROOT}/tmp/TRDC_{session_token}', \n",
    "                              docker_image=False, \n",
    "                              apply_preprocessing=False)\n",
    "\n",
    "print('Units found by tridesclous2:', sorting_TRDC.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_TRDC2 = ss.run_sorter('tridesclous2', recording=recording_cmr, \n",
    "                              output_folder=f'{ROOT}/tmp/TRDC2_{session_token}', \n",
    "                              docker_image=False, \n",
    "                              apply_preprocessing=False)\n",
    "\n",
    "print('Units found by tridesclous2:', sorting_TRDC2.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_MS5 = ss.run_sorter(sorter_name=\"mountainsort5\", recording=recording_cmr,output_folder=f'{ROOT}/tmp/MS5_{session_token}', \n",
    "                              docker_image=False)\n",
    "print('Units found by Mountainsort:', sorting_MS5.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TRDC2 = pd.DataFrame(sorting_TRDC2.to_spike_vector()).drop_duplicates(subset='sample_index').set_index('sample_index', drop=False)\n",
    "df_detect_peaks = pd.DataFrame(peaks).drop_duplicates(subset='sample_index').set_index('sample_index', drop=False)\n",
    "\n",
    "join_sample_index = np.intersect1d(df_TRDC2['sample_index'].values, df_detect_peaks['sample_index'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_TRDC2 = si.extract_waveforms(recording_cmr, sorting_TRDC2, folder=f'{ROOT}/tmp/TRDC2_WF_{session_token}',load_if_exists=False,\n",
    "    ms_before=1, ms_after=2.,\n",
    "    n_jobs=1, chunk_size=30000)\n",
    "\n",
    "sw.plot_unit_waveforms(we_TRDC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_MS5 = si.extract_waveforms(recording_cmr, sorting_MS5, folder=f'{ROOT}/tmp/MS5_WF_{session_token}',load_if_exists=False,\n",
    "    ms_before=1, ms_after=2.,\n",
    "    n_jobs=1, chunk_size=30000)\n",
    "\n",
    "sw.plot_unit_waveforms(we_MS5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.sortingcomponents.clustering import find_cluster_from_peaks\n",
    "labels, peak_labels_sliding_hdbscan = find_cluster_from_peaks(recording=recording_cmr, peaks=peaks, method=\"sliding_hdbscan\")\n",
    "\n",
    "# Me dice que too many open files????\n",
    "# labels, peak_labels_position_and_pca = find_cluster_from_peaks(recording=recording_cmr, peaks=peaks, method=\"position_and_pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(find_cluster_from_peaks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks = pd.DataFrame(peaks)\n",
    "\n",
    "df_peaks['sliding_hdbscan'] = peak_labels_sliding_hdbscan\n",
    "# df_peaks = df_peaks[df_peaks['sliding_hdbscan'] != -1]\n",
    "\n",
    "df_peaks['position_and_pca'] = peak_labels_position_and_pca\n",
    "# df_peaks = df_peaks[df_peaks['position_and_pca'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_peaks[['channel_index', 'sliding_hdbscan']].groupby(['channel_index', 'sliding_hdbscan']).size().reset_index(name='count')\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoneuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

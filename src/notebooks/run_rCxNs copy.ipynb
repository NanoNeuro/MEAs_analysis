{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING: Este notebook es experimental. Cuando todo funcione bien, habrá que crear un objeto que almacene toda la información de manera correcta y almacenar ahí todo. Habrá que diseñar el objeto de manera lógica, que almacene un canal por cada vez, para poder correr todos los algoritmos por separado, y para luego crear **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from probeinterface.plotting import plot_probe\n",
    "\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import spikeinterface.full as si  # import core only\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.curation as scur\n",
    "import spikeinterface.widgets as sw\n",
    "from spikeinterface.sortingcomponents.peak_detection import detect_peaks\n",
    "from spikeinterface.sortingcomponents.peak_localization import localize_peaks\n",
    "from spikeinterface.sortingcomponents.clustering import find_cluster_from_peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from py_functions.spikeinterface_processing import load_recording_from_raw_independent_channels, load_probe_recording, load_recording_from_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_job_kwargs = dict(n_jobs=10, chunk_duration=\"1s\", progress_bar=False)\n",
    "si.set_global_job_kwargs(**global_job_kwargs)\n",
    "plt.rcParams['figure.dpi'] = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN PARAMS\n",
    "ROOT = '/data/Proyectos/Nanoneuro/data/NeurTime/'\n",
    "SAMPLE_BASE = 'D13.postsiembra.p2(000)'\n",
    "well = (2, 3)\n",
    "time_samplings_to_mask = []\n",
    "type_MEAS = 16  # 16 or 64\n",
    "\n",
    "session_token = datetime.now().strftime(\"%y-%m-%d\") + '_' + \\\n",
    "                ''.join(random.choice(string.ascii_letters) for i in range(8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading & preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_dict = load_recording_from_raw_independent_channels(root=ROOT, sample_base=SAMPLE_BASE, well=well, time_samplings_to_mask=time_samplings_to_mask)\n",
    "for recording in recording_dict.values():\n",
    "    load_probe_recording(recording=recording['base_recording'], type_MEAS=type_MEAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel_id, recording_subdict in recording_dict.items():\n",
    "    recording = recording_subdict['base_recording']\n",
    "\n",
    "    recording_bin = recording.save(n_jobs=8, chunk_duration=\"1s\", folder=f'{ROOT}/tmp/bin_{session_token}_{channel_id}')\n",
    "    recording_subdict['binary_recording'] = recording_bin\n",
    "\n",
    "    recording_f = spre.bandpass_filter(recording_bin, freq_min=300, freq_max=5000)\n",
    "    recording_subdict['filter_recording'] = recording_f\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak detection & sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise detection - we use this beforehand to later use in peak detection\n",
    "for channel_id, recording_subdict in recording_dict.items():\n",
    "    noise_levels = si.get_noise_levels(recording_subdict['filter_recording'], return_scaled=False)\n",
    "    recording_subdict['noise_levels'] = noise_levels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel_id, recording_subdict in recording_dict.items():\n",
    "    peaks = detect_peaks(recording_subdict['filter_recording'],\n",
    "                        method='by_channel',\n",
    "                        detect_threshold=5,\n",
    "                        noise_levels=recording_subdict['noise_levels'],\n",
    "                        exclude_sweep_ms=1.5,\n",
    "                        **global_job_kwargs)\n",
    "    \n",
    "    recording_subdict['peaks'] = peaks\n",
    "\n",
    "    labels, peak_labels = find_cluster_from_peaks(recording_subdict['filter_recording'], \n",
    "                                                  peaks, \n",
    "                                                  method=\"sliding_hdbscan\", **global_job_kwargs)\n",
    "    \n",
    "    \n",
    "    recording_subdict['peak_labels'] = peak_labels\n",
    "    recording_subdict['labels'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = '1-2'\n",
    "\n",
    "ms_before, ms_after = 2, 3\n",
    "\n",
    "peak_max_times = [i[0] for i in recording_dict[channel_id]['peaks']]\n",
    "\n",
    "samp_freq = recording_dict[channel_id]['base_recording'].get_sampling_frequency()\n",
    "before_frames, after_frames = int(ms_before * samp_freq / 1000), int(ms_after * samp_freq / 1000)\n",
    "peak_voltages = np.zeros((len(peak_max_times), before_frames + after_frames))\n",
    "trace = recording_dict[channel_id]['base_recording'].get_traces().ravel()\n",
    "\n",
    "for idx, peak_time in enumerate(peak_max_times):\n",
    "    peak_voltages[idx, :] = trace[peak_time - before_frames: peak_time + after_frames]\n",
    "\n",
    "print(set(recording_dict[channel_id]['peak_labels']), recording_dict[channel_id]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {\n",
    "    -1: \"#D3D3D3\",    # Light gray\n",
    "    0: \"#FFC0CB\",     # Pink\n",
    "    1: \"#FFA07A\",     # Light salmon\n",
    "    2: \"#FFD700\",     # Gold\n",
    "    3: \"#FF4500\",     # Orange red\n",
    "    4: \"#FF8C00\",     # Dark orange\n",
    "    5: \"#FF1493\",     # Deep pink\n",
    "    6: \"#008080\",     # Teal\n",
    "    7: \"#00BFFF\",     # Deep sky blue\n",
    "    8: \"#800080\",     # Purple\n",
    "    9: \"#9ACD32\",     # Yellow green\n",
    "    10: \"#2E8B57\"     # Sea green\n",
    "}\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(set(recording_dict[channel_id]['peak_labels'])), figsize=(len(set(recording_dict[channel_id]['peak_labels'])) * 2, 2))\n",
    "\n",
    "for label in set(recording_dict[channel_id]['peak_labels']):\n",
    "    if label == -1:\n",
    "        axidx = 0\n",
    "    else:\n",
    "        axidx = label\n",
    "\n",
    "    subset_peak_voltages = peak_voltages[recording_dict[channel_id]['peak_labels'] == label, :]\n",
    "\n",
    "    # subsampling\n",
    "    choice = np.random.choice(subset_peak_voltages.shape[0], 50)\n",
    "    subset_peak_voltages = subset_peak_voltages[choice, :]\n",
    "\n",
    "    for idx in range(subset_peak_voltages.shape[0]):\n",
    "        axs[axidx].plot(np.arange(peak_voltages.shape[1]), subset_peak_voltages[idx, :], color=color_dict[label], alpha=0.15, linewidth=1 )\n",
    "\n",
    "    axs[axidx].plot(np.arange(peak_voltages.shape[1]), np.median(subset_peak_voltages, 0), color=color_dict[label] )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, whiten=False).fit(peak_voltages)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_coords = pca.fit_transform(peak_voltages)\n",
    "plt.scatter(pca_coords[:, 0], pca_coords[:, 1], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=5).fit_transform(peak_voltages)\n",
    "\n",
    "plt.scatter(tsne[:, 0], tsne[:, 1], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_pca = HDBSCAN(min_cluster_size=int(len(peak_voltages) ** 0.5), allow_single_cluster=True).fit(pca_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(set(hdb_pca.labels_))\n",
    "\n",
    "for label in labels:\n",
    "    idx_bool = hdb_pca.labels_ == label\n",
    "    plt.scatter(pca_coords[idx_bool, 0], pca_coords[idx_bool, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, color in zip(labels, ['blue', 'orange', 'green']):\n",
    "    for idx in np.argwhere(hdb_pca.labels_ == label).ravel()[0:1]:\n",
    "        plt.plot(np.arange(peak_voltages.shape[1]), peak_voltages[idx, :] , color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, color in zip(labels, ['blue', 'orange', 'green']):\n",
    "    for idx in np.argwhere(hdb_pca.labels_ == label).ravel()[1:2]:\n",
    "        plt.plot(np.arange(peak_voltages.shape[1]), peak_voltages[idx, :] , color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, color in zip(labels, ['blue', 'orange', 'green']): \n",
    "    median = np.median(pca_coords[hdb_pca.labels_ == label, :], 0)\n",
    "    voltage_median = pca.inverse_transform(median)\n",
    "    plt.plot(np.arange(peak_voltages.shape[1]), voltage_median , color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.get_default_sorter_params('tridesclous2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel_id, recording_subdict in recording_dict.items():   \n",
    "    sorting_MS4 = ss.run_sorter('mountainsort4', \n",
    "                                recording=recording_subdict['filter_recording'], \n",
    "                                output_folder=f'{ROOT}/tmp/MS4_{session_token}', \n",
    "                                docker_image=False)\n",
    "    print('Units found by mountainsort4:', sorting_MS4.get_unit_ids())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_all = load_recording_from_raw(root=ROOT, sample_base=SAMPLE_BASE, well=well, time_samplings_to_mask=time_samplings_to_mask)\n",
    "load_probe_recording(recording=recording_all, type_MEAS=type_MEAS)\n",
    "\n",
    "\n",
    "recording_bin = recording_all.save(n_jobs=8, chunk_duration=\"1s\", folder=f'{ROOT}/tmp/bin_{session_token}')\n",
    "\n",
    "recording_f = spre.bandpass_filter(recording_bin, freq_min=300, freq_max=5000)\n",
    "\n",
    "recording_cmr = spre.common_reference(recording_f, reference='global', operator='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = si.get_noise_levels(recording_cmr, return_scaled=False)\n",
    "\n",
    "local_radius = 150\n",
    "\n",
    "peaks = detect_peaks(recording_cmr,\n",
    "                     method='locally_exclusive',\n",
    "                     local_radius_um=local_radius, \n",
    "                     detect_threshold=5,\n",
    "                     noise_levels=noise_levels,\n",
    "                    **global_job_kwargs)\n",
    "\n",
    "peaks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts = si.plot_timeseries(recording_cmr, time_range=(300, 360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([i[0]/12500 for i in peaks], [i[1] for i in peaks], marker='|')\n",
    "plt.xlim([310, 315])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = detect_peaks(recording_cmr, method='by_channel', peak_sign='neg', detect_threshold=5, exclude_sweep_ms=2)\n",
    "\n",
    "labels, peak_labels = find_cluster_from_peaks(recording, peaks, method=\"sliding_hdbscan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_MS4 = ss.run_sorter('mountainsort4', recording=recording_cmr, output_folder=f'{ROOT}/tmp/MS5_{session_token}', docker_image=False)\n",
    "print('Units found by mountainsort4:', sorting_MS4.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_SPCR2 = ss.run_sorter('spykingcircus2', recording=recording_cmr, output_folder=f'{ROOT}/tmp/SPRC2_{session_token}', docker_image=False)\n",
    "print('Units found by spykingcircus2:', sorting_SPCR2.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_pyKS = ss.run_sorter('pykilosort', recording=recording_cmr, output_folder=f'{ROOT}/tmp/pyKS_{session_token}', \n",
    "                             docker_image=True) \n",
    "print('Units found by pykilosort:', sorting_pyKS.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we = si.extract_waveforms(recording_cmr, sorting_TRDC2, folder=f'{ROOT}/tmp/TRDC2_WF_{session_token}',load_if_exists=True,\n",
    "    ms_before=1, ms_after=2., max_spikes_per_unit=500,\n",
    "    n_jobs=1, chunk_size=30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA FROM SPK MATRICES\n",
    "\n",
    "df = pd.read_csv(f'{ROOT}/{SAMPLE_BASE}/{SAMPLE_BASE}.info', index_col=0, names=['index', 'value'], sep='\\t')\n",
    "sampling_frequency = df.loc['SamplingFrequency', 'value']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoneuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
